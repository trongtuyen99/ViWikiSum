keyword: Tổng hợp giọng nói
url: https://jobs.hybrid-technologies.vn/blog/cong-nghe-nhan-dang-va-gia-lap-giong-noi/
content:
AI (Artificial Intelligence) hay Trí tuệ nhân tạo là một ngành của khoa học máy tính liên quan đến việc tự động hóa các hành vi thông minh đã không còn quá xa lạ với chúng ta ở thời đại Công nghệ thông tin 4.0. Ứng dụng AI phổ biến hiện nay đó là Nhận dạng giọng nói. Công nghệ này không còn là một khái niệm mới mẻ, tất cả những ông lớn ngành công nghệ đều đã đang lấn sân vào “cuộc chơi” này. Đó là trợ lý ảo Siri của Apple, Cortana của Microsoft, Alexa của Amazon, đến cả Samsung cũng chập chững cho thai nghen trợ lý Bixby của riêng mình hay không thể không kể đến Google Assistant của Google. Nhận dạng giọng nói đã được biết đến hàng thập kỷ, tại sao chỉ đến bây giờ, công nghệ mới thực sự bùng nổ? Theo wikipedia, khó khăn cơ bản của nhận dạng giọng nói đó là tiếng nói luôn biến thiên theo thời gian và có sự khác biệt lớn giữa tiếng nói của những người nói khác nhau, tốc độ nói, ngữ cảnh và môi trường âm học khác nhau. Sự ra đời của Deep Learning đã giúp nhận diện giọng nói chính xác, thậm chí ở ngoài môi trường phòng lab. Ví dụ, đối với Google Assistant, bạn có thể dễ dàng tìm kiếm chỉ với giọng nói câu lệnh từ bạn. Nó là một phần của việc chuyển đổi giọng nói thành văn bản. Ở một mức độ cao hơn, Google Assistant có thể hiểu được câu nói của bạn và phản hồi lại với một kết quả có thể nói là gần như hoàn hảo. Để có thể có được một mức độ thông minh như vậy thì AI cần nguồn dữ liệu lớn để học hỏi, quá trình này do người dùng cung cấp cũng như do chính bạn tương tác thường xuyên với Google Assistant. Để AI thông minh thì cần phải có dữ liệu để huấn luyện cho nó, cả về nhận diện hình ảnh, văn bản, giọng nói. Google có hàng tỷ người dùng với công cụ tìm kiếm, nó có thể biết được trong khoảng thời gian nào, trong từng thời điểm người dùng quan tâm từ khóa nào, lĩnh vực nào. Đó là một cách người dùng tự tạo dữ liệu cho AI. Cũng còn một cách là người dùng trực tiếp cung cấp dữ liệu cho AI. Vậy người ta áp dụng công nghệ giọng nói vào phần mềm như thế nào? Thông thường một bộ máy giọng nói sẽ có hai phần. Phần thứ nhất gọi là Speech synthesizer (còn gọi là Text to Speech hay TTS). Đây là một trình tổng hợp giọng nói và thiết bị hoặc ứng dụng xài để tương tác với người dùng, ví dụ: đọc văn bản trên màn hình, thông báo về tiến độ chạy một tác vụ nào đó. Phần thứ hai là một công nghệ nhận dạng cho phép app biết được người dùng đang nói gì, từ đó chuyển thể thành lệnh để thiết bị thực thi hoặc chuyển đổi thành các kí tự nhập liệu. Nói cách khác, đây là thứ thay thế cho bàn phím của chúng ta. Một ứng dụng nhận dạng giọng nói lý tưởng sẽ bao gồm cả hai bộ phận nói trên, nhưng một số app chỉ xài một cái rồi từ từ nâng cấp sau. Thoạt nhìn thì việc triển khai công nghệ nhận dạng giọng nói khá đơn giản, nhưng thực chất thì không phải như thế. Thứ nhất, các nhà phát triển phải xây dựng nên một công nghệ có thể lắng nghe, phân tích và phiên dịch một cách chính xác giọng nói của người dùng. Nếu không thì làm sao app biết bạn đang nói gì, còn nếu độ chính xác không cao thì cũng như không. Thứ hai, vấn đề bản địa hóa (localization) cũng là một chuyện làm đau đầu các lập trình viên. Mỗi quốc gia sẽ có ngôn ngữ của riêng mình, vấn đề đó là làm thế nào để có thể hỗ trợ càng nhiều ngôn ngữ càng tốt. Có một kĩ thuật được nhắc đến nhiều trong thời gian gần đây, đó là Xử lý ngôn ngữ tự nhiên (Natural Language Processing – NLP). Nó là tập hợp của nhiều thuận toán phức tạp nhằm phân tích mệnh lệnh của người dùng nhưng không bắt buộc họ phải nói theo một cấu trúc câu định sẵn. Nhiều năm trước khi muốn điều khiển bằng giọng nói, bạn chỉ có thể nói những thứ như “Mở bản đồ”, “Nhắn tin cho vợ”, “Báo thức lúc 5 giờ sáng”. Còn bây giờ thì nhờ có NLP, chúng ta có thể nói các câu như “Siri, vui lòng nhắn tin cho vợ của tôi là tôi sẽ về trễ nhé”, hay như “Hãy đánh thức tôi lúc 5 giờ sáng ngày mai”. Điện toán đám mây: Trong trường hợp này, việc nhận dạng, xử lý ngôn ngữ sẽ diễn ra trên máy chủ của các công ty cung cấp dịch vụ. Phương pháp đám mây giúp việc nhận dạng được chính xác hơn, ứng dụng thì có dung lượng nhỏ, nhưng bù lại thì thiết bị ở phía người dùng phải luôn kết nối với Internet. Độ trễ trong quá trình gửi giọng nói từ máy lên server rồi trả kết quả từ server về lại máy cũng là những thứ đáng cân nhắc.
